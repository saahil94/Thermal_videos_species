{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils import layer_utils\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import datetime\n",
    "import gc\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.backend import clear_session\n",
    "import tensorflow as tf\n",
    "import random as python_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('WARNING')\n",
    "\n",
    "# set seeds\n",
    "np.random.seed(7654)\n",
    "python_random.seed(7654)\n",
    "tf.random.set_seed(7654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_NAME = ['rgb_kinetics_only', 'flow_kinetics_only', 'rgb_imagenet_and_kinetics', 'flow_imagenet_and_kinetics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to pretrained models with top (classification layer)\n",
    "WEIGHTS_PATH = {\n",
    "    'rgb_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels.h5',\n",
    "    'flow_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels.h5',\n",
    "    'rgb_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels.h5',\n",
    "    'flow_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels.h5'\n",
    "}\n",
    "\n",
    "# path to pretrained models with no top (no classification layer)\n",
    "WEIGHTS_PATH_NO_TOP = {\n",
    "    'rgb_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels_no_top.h5',\n",
    "    'flow_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels_no_top.h5',\n",
    "    'rgb_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels_no_top.h5',\n",
    "    'flow_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels_no_top.h5'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _obtain_input_shape(input_shape,\n",
    "                        default_frame_size,\n",
    "                        min_frame_size,\n",
    "                        default_num_frames,\n",
    "                        min_num_frames,\n",
    "                        data_format,\n",
    "                        require_flatten,\n",
    "                        weights=None):\n",
    "    \"\"\"Internal utility to compute/validate the model's input shape.\n",
    "    (Adapted from `keras/applications/imagenet_utils.py`)\n",
    "    # Arguments\n",
    "        input_shape: either None (will return the default network input shape),\n",
    "            or a user-provided shape to be validated.\n",
    "        default_frame_size: default input frames(images) width/height for the model.\n",
    "        min_frame_size: minimum input frames(images) width/height accepted by the model.\n",
    "        default_num_frames: default input number of frames(images) for the model.\n",
    "        min_num_frames: minimum input number of frames accepted by the model.\n",
    "        data_format: image data format to use.\n",
    "        require_flatten: whether the model is expected to\n",
    "            be linked to a classifier via a Flatten layer.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or 'kinetics_only' (pre-training on Kinetics dataset).\n",
    "            or 'imagenet_and_kinetics' (pre-training on ImageNet and Kinetics datasets).\n",
    "            If weights='kinetics_only' or weights=='imagenet_and_kinetics' then\n",
    "            input channels must be equal to 3.\n",
    "    # Returns\n",
    "        An integer shape tuple (may include None entries).\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument values.\n",
    "    \"\"\"\n",
    "    if weights != 'kinetics_only' and weights != 'imagenet_and_kinetics' and input_shape and len(input_shape) == 4:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape[0] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[0]) + ' input channels.')\n",
    "            default_shape = (input_shape[0], default_num_frames, default_frame_size, default_frame_size)\n",
    "        else:\n",
    "            if input_shape[-1] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[-1]) + ' input channels.')\n",
    "            default_shape = (default_num_frames, default_frame_size, default_frame_size, input_shape[-1])\n",
    "    else:\n",
    "        if data_format == 'channels_first':\n",
    "            default_shape = (3, default_num_frames, default_frame_size, default_frame_size)\n",
    "        else:\n",
    "            default_shape = (default_num_frames, default_frame_size, default_frame_size, 3)\n",
    "    if (weights == 'kinetics_only' or weights == 'imagenet_and_kinetics') and require_flatten:\n",
    "        if input_shape is not None:\n",
    "            if input_shape != default_shape:\n",
    "                raise ValueError('When setting`include_top=True` '\n",
    "                                 'and loading `imagenet` weights, '\n",
    "                                 '`input_shape` should be ' +\n",
    "                                 str(default_shape) + '.')\n",
    "        return default_shape\n",
    "\n",
    "    if input_shape:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 4:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of four integers.')\n",
    "                if input_shape[0] != 3 and (weights == 'kinetics_only' or weights == 'imagenet_and_kinetics'):\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "\n",
    "                if input_shape[1] is not None and input_shape[1] < min_num_frames:\n",
    "                    raise ValueError('Input number of frames must be at least ' +\n",
    "                                     str(min_num_frames) + '; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "\n",
    "                if ((input_shape[2] is not None and input_shape[2] < min_frame_size) or\n",
    "                   (input_shape[3] is not None and input_shape[3] < min_frame_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_frame_size) + 'x' + str(min_frame_size) + '; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "        else:\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 4:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of four integers.')\n",
    "                if input_shape[-1] != 3 and (weights == 'kinetics_only' or weights == 'imagenet_and_kinetics'):\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "\n",
    "                if input_shape[0] is not None and input_shape[0] < min_num_frames:\n",
    "                    raise ValueError('Input number of frames must be at least ' +\n",
    "                                     str(min_num_frames) + '; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "\n",
    "                if ((input_shape[1] is not None and input_shape[1] < min_frame_size) or\n",
    "                   (input_shape[2] is not None and input_shape[2] < min_frame_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_frame_size) + 'x' + str(min_frame_size) + '; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "    else:\n",
    "        if require_flatten:\n",
    "            input_shape = default_shape\n",
    "        else:\n",
    "            if data_format == 'channels_first':\n",
    "                input_shape = (3, None, None, None)\n",
    "            else:\n",
    "                input_shape = (None, None, None, 3)\n",
    "    if require_flatten:\n",
    "        if None in input_shape:\n",
    "            raise ValueError('If `include_top` is True, '\n",
    "                             'you should specify a static `input_shape`. '\n",
    "                             'Got `input_shape=' + str(input_shape) + '`')\n",
    "    return input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3d_bn(x,\n",
    "              filters,\n",
    "              num_frames,\n",
    "              num_row,\n",
    "              num_col,\n",
    "              padding='same',\n",
    "              strides=(1, 1, 1),\n",
    "              use_bias = False,\n",
    "              use_activation_fn = True,\n",
    "              use_bn = True,\n",
    "              name=None):\n",
    "    \"\"\"Utility function to apply conv3d + BN.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: filters in `Conv3D`.\n",
    "        num_frames: frames (time depth) of the convolution kernel.\n",
    "        num_row: height of the convolution kernel.\n",
    "        num_col: width of the convolution kernel.\n",
    "        padding: padding mode in `Conv3D`.\n",
    "        strides: strides in `Conv3D`.\n",
    "        use_bias: use bias or not  \n",
    "        use_activation_fn: use an activation function or not.\n",
    "        use_bn: use batch normalization or not.\n",
    "        name: name of the ops; will become `name + '_conv'`\n",
    "            for the convolution and `name + '_bn'` for the\n",
    "            batch norm layer.\n",
    "    # Returns\n",
    "        Output tensor after applying `Conv3D` and `BatchNormalization`.\n",
    "    \"\"\"\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "\n",
    "    x = Conv3D(\n",
    "        filters, (num_frames, num_row, num_col),\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        use_bias=use_bias,\n",
    "        name=conv_name)(x)\n",
    "\n",
    "    if use_bn:\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            bn_axis = 1\n",
    "        else:\n",
    "            bn_axis = 4\n",
    "        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "\n",
    "    if use_activation_fn:\n",
    "        x = Activation('relu', name=name)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception_Inflated3d(include_top=True,\n",
    "                weights=None,\n",
    "                input_tensor=None,\n",
    "                input_shape=None,\n",
    "                dropout_prob=0.0,\n",
    "                endpoint_logit=True,\n",
    "                classes=400):\n",
    "    \"\"\"Instantiates the Inflated 3D Inception v1 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on Kinetics. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format='channels_last'` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    Note that the default input frame(image) size for this model is 224x224.\n",
    "    # Arguments\n",
    "        include_top: whether to include the the classification \n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or 'kinetics_only' (pre-training on Kinetics dataset only).\n",
    "            or 'imagenet_and_kinetics' (pre-training on ImageNet and Kinetics datasets).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(NUM_FRAMES, 224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(NUM_FRAMES, 3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels.\n",
    "            NUM_FRAMES should be no smaller than 8. The authors used 64\n",
    "            frames per example for training and testing on kinetics dataset\n",
    "            Also, Width and height should be no smaller than 32.\n",
    "            E.g. `(64, 150, 150, 3)` would be one valid value.\n",
    "        dropout_prob: optional, dropout probability applied in dropout layer\n",
    "            after global average pooling layer. \n",
    "            0.0 means no dropout is applied, 1.0 means dropout is applied to all features.\n",
    "            Note: Since Dropout is applied just before the classification\n",
    "            layer, it is only useful when `include_top` is set to True.\n",
    "        endpoint_logit: (boolean) optional. If True, the model's forward pass\n",
    "            will end at producing logits. Otherwise, softmax is applied after producing\n",
    "            the logits to produce the class probabilities prediction. Setting this parameter \n",
    "            to True is particularly useful when you want to combine results of rgb model\n",
    "            and optical flow model.\n",
    "            - `True` end model forward pass at logit output\n",
    "            - `False` go further after logit to produce softmax predictions\n",
    "            Note: This parameter is only useful when `include_top` is set to True.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if not (weights in WEIGHTS_NAME or weights is None or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or %s' % \n",
    "                         str(WEIGHTS_NAME) + ' ' \n",
    "                         'or a valid path to a file containing `weights` values')\n",
    "\n",
    "    if weights in WEIGHTS_NAME and include_top and classes != 400:\n",
    "        raise ValueError('If using `weights` as one of these %s, with `include_top`'\n",
    "                         ' as true, `classes` should be 400' % str(WEIGHTS_NAME))\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(\n",
    "        input_shape,\n",
    "        default_frame_size=224, \n",
    "        min_frame_size=32, \n",
    "        default_num_frames=64,\n",
    "        min_num_frames=8,\n",
    "        data_format=K.image_data_format(),\n",
    "        require_flatten=include_top,\n",
    "        weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = 4\n",
    "\n",
    "    # Downsampling via convolution (spatial and temporal)\n",
    "    x = conv3d_bn(img_input, 64, 7, 7, 7, strides=(2, 2, 2), padding='same', name='Conv3d_1a_7x7')\n",
    "\n",
    "    # Downsampling (spatial only)\n",
    "    x = MaxPooling3D((1, 3, 3), strides=(1, 2, 2), padding='same', name='MaxPool2d_2a_3x3')(x)\n",
    "    x = conv3d_bn(x, 64, 1, 1, 1, strides=(1, 1, 1), padding='same', name='Conv3d_2b_1x1')\n",
    "    x = conv3d_bn(x, 192, 3, 3, 3, strides=(1, 1, 1), padding='same', name='Conv3d_2c_3x3')\n",
    "\n",
    "    # Downsampling (spatial only)\n",
    "    x = MaxPooling3D((1, 3, 3), strides=(1, 2, 2), padding='same', name='MaxPool2d_3a_3x3')(x)\n",
    "\n",
    "    # Mixed 3b\n",
    "    branch_0 = conv3d_bn(x, 64, 1, 1, 1, padding='same', name='Conv3d_3b_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 96, 1, 1, 1, padding='same', name='Conv3d_3b_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 128, 3, 3, 3, padding='same', name='Conv3d_3b_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 16, 1, 1, 1, padding='same', name='Conv3d_3b_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 32, 3, 3, 3, padding='same', name='Conv3d_3b_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_3b_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 32, 1, 1, 1, padding='same', name='Conv3d_3b_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_3b')\n",
    "\n",
    "    # Mixed 3c\n",
    "    branch_0 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_3c_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_3c_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 192, 3, 3, 3, padding='same', name='Conv3d_3c_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_3c_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 96, 3, 3, 3, padding='same', name='Conv3d_3c_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_3c_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_3c_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_3c')\n",
    "\n",
    "\n",
    "    # Downsampling (spatial and temporal)\n",
    "    x = MaxPooling3D((3, 3, 3), strides=(2, 2, 2), padding='same', name='MaxPool2d_4a_3x3')(x)\n",
    "\n",
    "    # Mixed 4b\n",
    "    branch_0 = conv3d_bn(x, 192, 1, 1, 1, padding='same', name='Conv3d_4b_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 96, 1, 1, 1, padding='same', name='Conv3d_4b_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 208, 3, 3, 3, padding='same', name='Conv3d_4b_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 16, 1, 1, 1, padding='same', name='Conv3d_4b_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 48, 3, 3, 3, padding='same', name='Conv3d_4b_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4b_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4b_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_4b')\n",
    "\n",
    "    # Mixed 4c\n",
    "    branch_0 = conv3d_bn(x, 160, 1, 1, 1, padding='same', name='Conv3d_4c_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 112, 1, 1, 1, padding='same', name='Conv3d_4c_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 224, 3, 3, 3, padding='same', name='Conv3d_4c_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 24, 1, 1, 1, padding='same', name='Conv3d_4c_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4c_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4c_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4c_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_4c')\n",
    "\n",
    "    # Mixed 4d\n",
    "    branch_0 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_4d_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_4d_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 256, 3, 3, 3, padding='same', name='Conv3d_4d_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 24, 1, 1, 1, padding='same', name='Conv3d_4d_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4d_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4d_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4d_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_4d')\n",
    "\n",
    "    # Mixed 4e\n",
    "    branch_0 = conv3d_bn(x, 112, 1, 1, 1, padding='same', name='Conv3d_4e_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 144, 1, 1, 1, padding='same', name='Conv3d_4e_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 288, 3, 3, 3, padding='same', name='Conv3d_4e_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_4e_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4e_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4e_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4e_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_4e')\n",
    "\n",
    "    # Mixed 4f\n",
    "    branch_0 = conv3d_bn(x, 256, 1, 1, 1, padding='same', name='Conv3d_4f_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 160, 1, 1, 1, padding='same', name='Conv3d_4f_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 320, 3, 3, 3, padding='same', name='Conv3d_4f_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_4f_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_4f_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4f_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_4f_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_4f')\n",
    "\n",
    "\n",
    "    # Downsampling (spatial and temporal)\n",
    "    x = MaxPooling3D((2, 2, 2), strides=(2, 2, 2), padding='same', name='MaxPool2d_5a_2x2')(x)\n",
    "\n",
    "    # Mixed 5b\n",
    "    branch_0 = conv3d_bn(x, 256, 1, 1, 1, padding='same', name='Conv3d_5b_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 160, 1, 1, 1, padding='same', name='Conv3d_5b_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 320, 3, 3, 3, padding='same', name='Conv3d_5b_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_5b_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_5b_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_5b_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_5b_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_5b')\n",
    "\n",
    "    # Mixed 5c\n",
    "    branch_0 = conv3d_bn(x, 384, 1, 1, 1, padding='same', name='Conv3d_5c_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 192, 1, 1, 1, padding='same', name='Conv3d_5c_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 384, 3, 3, 3, padding='same', name='Conv3d_5c_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 48, 1, 1, 1, padding='same', name='Conv3d_5c_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_5c_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_5c_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_5c_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_5c')\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = AveragePooling3D((2, 7, 7), strides=(1, 1, 1), padding='valid', name='global_avg_pool')(x)\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "\n",
    "        x = conv3d_bn(x, classes, 1, 1, 1, padding='same', \n",
    "                use_bias=True, use_activation_fn=False, use_bn=False, name='Conv3d_6a_1x1')\n",
    " \n",
    "        num_frames_remaining = int(x.shape[1])\n",
    "        x = Reshape((num_frames_remaining, classes))(x)\n",
    "\n",
    "        # logits (raw scores for each class)\n",
    "        x = Lambda(lambda x: K.mean(x, axis=1, keepdims=False),\n",
    "                   output_shape=lambda s: (s[0], s[2]))(x)\n",
    "\n",
    "        if not endpoint_logit:\n",
    "            x = Activation('softmax', name='prediction')(x)\n",
    "    else:\n",
    "        h = int(x.shape[2])\n",
    "        w = int(x.shape[3])\n",
    "        x = AveragePooling3D((2, h, w), strides=(1, 1, 1), padding='valid', name='global_avg_pool')(x)\n",
    "\n",
    "\n",
    "\n",
    "    inputs = img_input\n",
    "    # create model\n",
    "    model = Model(inputs, x, name='i3d_inception')\n",
    "\n",
    "    # load weights\n",
    "    if weights in WEIGHTS_NAME:\n",
    "        if weights == WEIGHTS_NAME[0]:   # rgb_kinetics_only\n",
    "            if include_top:\n",
    "                weights_url = WEIGHTS_PATH['rgb_kinetics_only']\n",
    "                model_name = 'i3d_inception_rgb_kinetics_only.h5'\n",
    "            else:\n",
    "                weights_url = WEIGHTS_PATH_NO_TOP['rgb_kinetics_only']\n",
    "                model_name = 'i3d_inception_rgb_kinetics_only_no_top.h5'\n",
    "\n",
    "        elif weights == WEIGHTS_NAME[1]: # flow_kinetics_only\n",
    "            if include_top:\n",
    "                weights_url = WEIGHTS_PATH['flow_kinetics_only']\n",
    "                model_name = 'i3d_inception_flow_kinetics_only.h5'\n",
    "            else:\n",
    "                weights_url = WEIGHTS_PATH_NO_TOP['flow_kinetics_only']\n",
    "                model_name = 'i3d_inception_flow_kinetics_only_no_top.h5'\n",
    "\n",
    "        elif weights == WEIGHTS_NAME[2]: # rgb_imagenet_and_kinetics\n",
    "            if include_top:\n",
    "                weights_url = WEIGHTS_PATH['rgb_imagenet_and_kinetics']\n",
    "                model_name = 'i3d_inception_rgb_imagenet_and_kinetics.h5'\n",
    "            else:\n",
    "                weights_url = WEIGHTS_PATH_NO_TOP['rgb_imagenet_and_kinetics']\n",
    "                model_name = 'i3d_inception_rgb_imagenet_and_kinetics_no_top.h5'\n",
    "\n",
    "        elif weights == WEIGHTS_NAME[3]: # flow_imagenet_and_kinetics\n",
    "            if include_top:\n",
    "                weights_url = WEIGHTS_PATH['flow_imagenet_and_kinetics']\n",
    "                model_name = 'i3d_inception_flow_imagenet_and_kinetics.h5'\n",
    "            else:\n",
    "                weights_url = WEIGHTS_PATH_NO_TOP['flow_imagenet_and_kinetics']\n",
    "                model_name = 'i3d_inception_flow_imagenet_and_kinetics_no_top.h5'\n",
    "\n",
    "        downloaded_weights_path = get_file(model_name, weights_url, cache_subdir='models')\n",
    "        model.load_weights(downloaded_weights_path)\n",
    "\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n",
    "            warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                          'are using the Theano '\n",
    "                          'image data format convention '\n",
    "                          '(`image_data_format=\"channels_first\"`). '\n",
    "                          'For best performance, set '\n",
    "                          '`image_data_format=\"channels_last\"` in '\n",
    "                          'your keras config '\n",
    "                          'at ~/.keras/keras.json.')\n",
    "\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(name):\n",
    "    X = np.load(\"C:/Users/Saahil/OneDrive/Documents/COMPSCI 760/Research Project/cacophony-preprocessed\" + name + \".npy\")\n",
    "    y = np.load(\"C:/Users/Saahil/OneDrive/Documents/COMPSCI 760/Research Project/cacophony-preprocessed\" + name + \"-labels.npy\")\n",
    "    y_one_hot_encoded = np.zeros([y.shape[0], np.unique(y).size])\n",
    "    y_one_hot_encoded[range(y.shape[0]), y] = 1\n",
    "    return X, y_one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_joint_model(upscaling, d_1, d_2, d_3, f_1, r_1, r_2, pooling):\n",
    "\n",
    "    MLP = Sequential()\n",
    "    MLP.add(Flatten())\n",
    "    MLP.add(Dropout(d_1))\n",
    "    MLP.add(Dense(f_1, activation = \"relu\"))\n",
    "    MLP.add(Dense(13, activation=\"softmax\"))\n",
    "\n",
    "    vid_inputs = Input((45, upscaling, upscaling, 3))\n",
    "    mvm_inputs = Input((45, 9))\n",
    "\n",
    "    # CNN extracts 512 video features for each frame\n",
    "    x = Inception_Inflated3d(include_top = False,\n",
    "                         weights = 'rgb_imagenet_and_kinetics',\n",
    "                         input_shape = (45, upscaling, upscaling, 3))(vid_inputs)\n",
    "\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "  \n",
    "    vid_features = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    # LSTM extracts 512 movement features for each frame\n",
    "    mvm_features = LSTM(r_1, return_sequences=True, dropout = d_2, recurrent_dropout = 0.0)(mvm_inputs)\n",
    "    if pooling == 'avg':\n",
    "        mvm_features = AveragePooling1D(pool_size=1, strides=9)(mvm_features)\n",
    "    elif pooling == 'max':\n",
    "        mvm_features = MaxPooling1D(pool_size=1, strides=9)(mvm_features)\n",
    "    # Concatenating for 1024 features for each frame\n",
    "    x = Concatenate()([vid_features, mvm_features])\n",
    "    # LSTM across both image and movement data\n",
    "    x = LSTM(r_2, return_sequences = True, dropout = d_3, recurrent_dropout = 0.0)(x)\n",
    "    # MLP makes a classification for each frame\n",
    "    x = TimeDistributed(MLP)(x)\n",
    "    # Outputting the mean classification of all frames\n",
    "    outputs = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    model = Model(inputs=[vid_inputs, mvm_inputs], outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, vids, mvm, labels, batch_size, upscaling, flip = False, angle = 0, crop = 0, shift = 0, shuffle = True):\n",
    "        self.vids = vids\n",
    "        self.mvm = mvm\n",
    "        self.labels = labels\n",
    "        self.indices = np.arange(vids.shape[0])\n",
    "        self.batch_size = batch_size\n",
    "        self.flip = flip\n",
    "        self.angle = angle\n",
    "        self.crop = crop\n",
    "        self.shift = shift\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def random_zoom(self, batch, x, y):\n",
    "        ax = np.random.uniform(self.crop)\n",
    "        bx = np.random.uniform(ax)\n",
    "        ay = np.random.uniform(self.crop)\n",
    "        by = np.random.uniform(ay)\n",
    "        x = x*(1-ax/batch.shape[2]) + bx\n",
    "        y = y*(1-ay/batch.shape[3]) + by\n",
    "        return x, y\n",
    "\n",
    "    def random_rotate(self, batch, x, y):\n",
    "        rad = np.random.uniform(-self.angle, self.angle)/180*np.pi\n",
    "        rotm = np.array([[np.cos(rad),  np.sin(rad)],\n",
    "                         [-np.sin(rad), np.cos(rad)]])\n",
    "        xm, ym = x.mean(), y.mean()\n",
    "        x, y = np.einsum('ji, mni -> jmn', rotm, np.dstack([x-xm, y-ym]))\n",
    "        return x+xm, y+ym\n",
    "\n",
    "    def random_translate(self, batch, x, y):\n",
    "        xs = np.random.uniform(-self.shift, self.shift)\n",
    "        ys = np.random.uniform(-self.shift, self.shift)\n",
    "        return x + xs, y + ys\n",
    "\n",
    "    def horizontal_flip(self, batch):\n",
    "        return np.flip(batch, 3)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        vids = np.array(self.vids[indices])\n",
    "        #x, y = np.meshgrid(range(vids.shape[2]), range(vids.shape[3]))\n",
    "        x, y = np.meshgrid(np.arange(upscaling)*(24 / upscaling), np.arange(upscaling)*(24 / upscaling))\n",
    "        if self.crop:\n",
    "            x, y = self.random_zoom(vids, x, y)\n",
    "        if self.angle:\n",
    "            x, y = self.random_rotate(vids, x, y)\n",
    "        if self.shift:\n",
    "            x, y = self.random_translate(vids, x, y)\n",
    "        if self.flip and np.random.random() < 0.5:\n",
    "            vids = self.horizontal_flip(vids)\n",
    "        x = np.clip(x, 0, vids.shape[2]-1).astype(np.int)\n",
    "        y = np.clip(y, 0, vids.shape[3]-1).astype(np.int)\n",
    "        vids = vids[:,:,x,y].transpose(0,1,3,2,4)\n",
    "        if self.mvm is not None:\n",
    "            out = [vids, self.mvm[indices]], self.labels[indices]\n",
    "        else:\n",
    "            out = vids, self.labels[indices]\n",
    "        return out\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(history):\n",
    "\n",
    "    # plot training history\n",
    "    # two plots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('model accuracy')\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('model loss')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    fig.savefig('./logs/plot' + current_time + '.svg', format = 'svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loading.. "
     ]
    }
   ],
   "source": [
    "print(\"Dataset loading..\", end = \" \")\n",
    "# Loading the preprocessed videos\n",
    "X_train, y_train = load(\"/training\")\n",
    "X_val, y_val = load(\"/validation\")\n",
    "X_test, y_test = load(\"/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Keras likes the channels last data format\n",
    "X_train = X_train.transpose(0,1,3,4,2)\n",
    "X_val = X_val.transpose(0,1,3,4,2)\n",
    "X_test = X_test.transpose(0,1,3,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded!\n"
     ]
    }
   ],
   "source": [
    "# Loading the preprocessed movement features\n",
    "X_train_mvm, _ = load(\"-movement/training\")\n",
    "X_val_mvm, _ = load(\"-movement/validation\")\n",
    "X_test_mvm, _ = load(\"-movement/test\")\n",
    "print(\"Dataset loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k-fold we want to use both train and validation data to generate the folds\n",
    "# holdout stays apart\n",
    "X_train2 = np.concatenate((X_train, X_val))\n",
    "X_train_mvm2 = np.concatenate((X_train_mvm, X_val_mvm))\n",
    "y_train2 = np.concatenate((y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = str(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create log dir\n",
    "if not os.path.exists(\"./logs/kfold\"):\n",
    "    os.makedirs(\"./logs/kfold\")\n",
    "\n",
    "if not os.path.exists(\"./logs/kfold_plotdata\"):\n",
    "    os.makedirs(\"./logs/kfold_plotdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "upscaling = 32 # from 24x24\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(key):\n",
    "    models = dict()\n",
    "    models['i3d-1'] = define_joint_model(upscaling, d_1 = 0.5, d_2 = 0.2, d_3 = 0.2, f_1 = 256, r_1 = 512, r_2 = 512, pooling = 'avg')\n",
    "    models['i3d-2'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.2, d_3 = 0.2, f_1 = 256, r_1 = 512, r_2 = 512, pooling = 'avg')\n",
    "    models['i3d-3'] = define_joint_model(upscaling, d_1 = 0.5, d_2 = 0.1, d_3 = 0.1, f_1 = 256, r_1 = 512, r_2 = 512, pooling = 'avg')\n",
    "    models['i3d-4'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.1, d_3 = 0.1, f_1 = 256, r_1 = 512, r_2 = 512, pooling = 'avg')\n",
    "    models['i3d-5'] = define_joint_model(upscaling, d_1 = 0.5, d_2 = 0.2, d_3 = 0.2, f_1 = 256, r_1 = 512, r_2 = 512, pooling = 'max')\n",
    "    models['i3d-6'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.2, d_3 = 0.2, f_1 = 256, r_1 = 512, r_2 = 512, pooling = 'max')\n",
    "    models['i3d-7'] = define_joint_model(upscaling, d_1 = 0.5, d_2 = 0.1, d_3 = 0.1, f_1 = 256, r_1 = 512, r_2 = 512, pooling = 'max')\n",
    "    models['i3d-8'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.1, d_3 = 0.1, f_1 = 256, r_1 = 512, r_2 = 512, pooling = 'max')\n",
    "    models['i3d-9'] = define_joint_model(upscaling, d_1 = 0.5, d_2 = 0.2, d_3 = 0.2, f_1 = 512, r_1 = 512, r_2 = 512, pooling = 'avg')\n",
    "    models['i3d-10'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.2, d_3 = 0.2, f_1 = 512, r_1 = 512, r_2 = 512, pooling = 'avg')\n",
    "    models['i3d-11'] = define_joint_model(upscaling, d_1 = 0.5, d_2 = 0.1, d_3 = 0.1, f_1 = 512, r_1 = 512, r_2 = 512, pooling = 'avg')\n",
    "    models['i3d-12'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.1, d_3 = 0.1, f_1 = 512, r_1 = 512, r_2 = 512, pooling = 'avg')\n",
    "    models['i3d-13'] = define_joint_model(upscaling, d_1 = 0.5, d_2 = 0.2, d_3 = 0.2, f_1 = 512, r_1 = 512, r_2 = 512, pooling = 'max')\n",
    "    models['i3d-14'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.2, d_3 = 0.2, f_1 = 512, r_1 = 512, r_2 = 512, pooling = 'max')\n",
    "    models['i3d-15'] = define_joint_model(upscaling, d_1 = 0.5, d_2 = 0.1, d_3 = 0.1, f_1 = 512, r_1 = 512, r_2 = 512, pooling = 'max')\n",
    "    models['i3d-16'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.1, d_3 = 0.1, f_1 = 512, r_1 = 512, r_2 = 512, pooling = 'max')\n",
    "\n",
    "    models['i3d-17'] = define_joint_model(upscaling, d_1 = 0.3, d_2 = 0.3, d_3 = 0.3, f_1 = 256, r_1 = 512, r_2 = 512, pooling = 'avg')\n",
    "    models['i3d-18'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.2, d_3 = 0.2, f_1 = 256, r_1 = 256, r_2 = 256, pooling = 'avg')\n",
    "    models['i3d-19'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.2, d_3 = 0.2, f_1 = 256, r_1 = 512, r_2 = 256, pooling = 'avg')\n",
    "    models['i3d-20'] = define_joint_model(upscaling, d_1 = 0.5, d_2 = 0.2, d_3 = 0.2, f_1 = 512, r_1 = 512, r_2 = 512, pooling = 'avg')\n",
    "    models['i3d-21'] = define_joint_model(upscaling, d_1 = 0.6, d_2 = 0.3, d_3 = 0.3, f_1 = 512, r_1 = 512, r_2 = 1024, pooling = 'avg')\n",
    "    models['i3d-22'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.2, d_3 = 0.2, f_1 = 256, r_1 = 512, r_2 = 1024, pooling = 'avg')\n",
    "    models['i3d-23'] = define_joint_model(upscaling, d_1 = 0.1, d_2 = 0.1, d_3 = 0.1, f_1 = 128, r_1 = 256, r_2 = 256, pooling = 'avg')\n",
    "    models['i3d-24'] = define_joint_model(upscaling, d_1 = 0.2, d_2 = 0.2, d_3 = 0.2, f_1 = 128, r_1 = 256, r_2 = 256, pooling = 'avg')\n",
    "    models['i3d-25'] = define_joint_model(upscaling, d_1 = 0.4, d_2 = 0.2, d_3 = 0.2, f_1 = 256, r_1 = 512, r_2 = 512, pooling = 'avg')\n",
    "    return models[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, name):\n",
    "    model_accuracy = []\n",
    "    model_loss = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X = np.zeros(X_train2.shape[0]), y = y_train2.argmax(1))): # because split returns incidies we only need one\n",
    "        # csv logs based on the time\n",
    "        model.compile(loss='categorical_crossentropy', optimizer = Adam(lr = learning_rate), metrics=[\"accuracy\"])\n",
    "        #print(model.summary())\n",
    "        csv_logger = CSVLogger('./logs/kfold/log_' + str(fold + 1) +'_'+name + '.csv', append=True, separator=';')\n",
    "        reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.5, patience = 3, min_lr = 0.00001, verbose = 1)\n",
    "        checkpointer = ModelCheckpoint(filepath='./logs/kfold/best_weights_fold' + str(fold + 1) +'_'+name + '.hdf5', verbose=1, save_best_only=True, monitor='val_accuracy', mode = 'max')\n",
    "        callbacks = [EarlyStopping(patience = 10), reduce_lr, csv_logger, checkpointer]\n",
    "    \n",
    "        # get data\n",
    "        X_train, X_train_mvm, y_train = X_train2[train_idx], X_train_mvm2[train_idx], y_train2[train_idx]\n",
    "        X_val, X_val_mvm, y_val = X_train2[val_idx], X_train_mvm2[val_idx], y_train2[val_idx]\n",
    "        train_data = DataGenerator(X_train, X_train_mvm, y_train, batch_size, upscaling, True, 10, 0, 0)\n",
    "        val_data = DataGenerator(X_val, X_val_mvm, y_val, batch_size, upscaling)\n",
    "        #test_data = DataGenerator(X_test, X_test_mvm, y_test, batch_size, upscaling)\n",
    "    #    data_x.extend(X_val)\n",
    "    #    data_mvm.extend(X_val_mvm)\n",
    "    #    data_y.extend(y_val)\n",
    "        # fit model\n",
    "        print('Training fold ' + str(fold + 1) + ' of ' + name + ' with augmentation...')\n",
    "    #   model = define_model_LRCN()\n",
    "        model.save_weights('model.h5')       \n",
    "        history = model.fit(train_data,\n",
    "              epochs = epochs,\n",
    "              validation_data = val_data,\n",
    "              callbacks = callbacks,\n",
    "              verbose = 0)\n",
    "        best_epoch = np.argmax(history.history['val_accuracy'])\n",
    "        model_accuracy.append(history.history['val_accuracy'][best_epoch])\n",
    "        model_loss.append(history.history['val_loss'][best_epoch])\n",
    "        model.load_weights('model.h5')\n",
    "        #preds = model.predict([X_val, X_val_mvm], batch_size = batch_size)[:, 0]\n",
    "        #preds_lrcn.extend(preds)\n",
    "        plots(history)\n",
    "    del model\n",
    "    clear_session()\n",
    "    #tf.keras.backend.clear_session()\n",
    "    return np.asarray(model_accuracy).flatten(), np.asarray(model_loss).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_acc, box_loss, names = list(), list(), list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1 of i3d-17 with augmentation...\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69408, saving model to ./logs/kfold\\best_weights_fold1_i3d-17.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.69408\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.69408 to 0.76042, saving model to ./logs/kfold\\best_weights_fold1_i3d-17.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.76042 to 0.76151, saving model to ./logs/kfold\\best_weights_fold1_i3d-17.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.76151\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.76151\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.76151 to 0.77632, saving model to ./logs/kfold\\best_weights_fold1_i3d-17.hdf5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.77632 to 0.80482, saving model to ./logs/kfold\\best_weights_fold1_i3d-17.hdf5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80482\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80482\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.80482 to 0.82072, saving model to ./logs/kfold\\best_weights_fold1_i3d-17.hdf5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82072\n"
     ]
    }
   ],
   "source": [
    "for name in ['i3d-17', 'i3d-18', 'i3d-19', 'i3d-20', 'i3d-21', 'i3d-22', 'i3d-23', 'i3d-24', 'i3d-25']:\n",
    "    model = get_model(name)\n",
    "    val_acc, val_loss = evaluate_model(model, name)\n",
    "    del model\n",
    "#    models.pop(name, None)\n",
    "    clear_session()\n",
    "    #tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    box_acc.append(val_acc)\n",
    "    box_loss.append(val_loss)\n",
    "    names.append(name)\n",
    "    with open('./logs/kfold_plotdata/plotdata_box_acc_' + name + '.csv', \"wb\") as fp:\n",
    "        pickle.dump(box_acc, fp)\n",
    "    with open('./logs/kfold_plotdata/plotdata_box_loss_' + name + '.csv', \"wb\") as fp:\n",
    "        pickle.dump(box_loss, fp)\n",
    "    with open('./logs/kfold_plotdata/plotdata_names_' + name + '.csv', \"wb\") as fp:\n",
    "        pickle.dump(names, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "ax1.boxplot(box_acc, labels = names, showmeans = True)\n",
    "ax2.set_title('val accuracy')\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.set_xlabel('model')\n",
    "\n",
    "ax2.boxplot(box_loss, labels = names, showmeans = True)\n",
    "ax2.set_title('val loss')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_xlabel('model')\n",
    "\n",
    "fig.savefig('./logs/kfold' + current_time + '/plot_val_acc_cv' + current_time + '.svg', format = 'svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
